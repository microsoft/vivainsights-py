{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bdb433",
   "metadata": {},
   "source": [
    "# Demo: Information Value Analysis with vivainsights\n",
    "\n",
    "This notebook demonstrates how to use **Information Value (IV)** analysis with the **vivainsights** Python package to assess the predictive strength of organizational variables for collaboration outcomes.\n",
    "\n",
    "## What is Information Value?\n",
    "\n",
    "Information Value is a powerful statistical technique that quantifies how well a variable separates different outcome groups. It's particularly useful for:\n",
    "\n",
    "- **Feature selection** in predictive modeling\n",
    "- **Identifying key drivers** of business outcomes\n",
    "- **Data quality assessment** by detecting suspicious relationships\n",
    "- **Variable screening** before advanced analytics\n",
    "\n",
    "### Information Value Interpretation Guide:\n",
    "\n",
    "- **IV < 0.02**: Not useful for prediction (no relationship)\n",
    "- **0.02 ≤ IV < 0.1**: Weak predictive power\n",
    "- **0.1 ≤ IV < 0.3**: Medium predictive power  \n",
    "- **0.3 ≤ IV < 0.5**: Strong predictive power\n",
    "- **IV ≥ 0.5**: Very strong (potentially suspicious - check for data leakage)\n",
    "\n",
    "## When to Use Information Value Analysis:\n",
    "\n",
    "🎯 **Business Applications:**\n",
    "- Identify which organizational attributes drive high collaboration\n",
    "- Screen variables before building predictive models\n",
    "- Validate business hypotheses about engagement drivers\n",
    "- Assess data quality and detect potential issues\n",
    "\n",
    "🔍 **Technical Applications:**\n",
    "- Feature selection for machine learning models\n",
    "- Variable importance ranking\n",
    "- Data leakage detection\n",
    "- Dimensionality reduction guidance\n",
    "\n",
    "In this walkthrough, you will learn to:\n",
    "1. Calculate IV for individual variables\n",
    "2. Perform batch IV analysis across multiple variables\n",
    "3. Visualize and interpret IV results\n",
    "4. Apply best practices for IV analysis in organizational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60be0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import vivainsights as vi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c5f9b",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Demo Data\n",
    "\n",
    "First, let's load the sample Person Query dataset and prepare it for Information Value analysis. We'll create a meaningful binary outcome variable and identify predictor variables for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e9f39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Dataset Overview:\n",
      "  Shape: 10,500 rows × 73 columns\n",
      "  Date range: 2024-03-31 to 2024-11-24\n",
      "  Unique employees: 300\n",
      "  Time periods: 35 unique weeks\n",
      "\n",
      "📋 Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonId</th>\n",
       "      <th>MetricDate</th>\n",
       "      <th>Collaboration_hours</th>\n",
       "      <th>Copilot_actions_taken_in_Teams</th>\n",
       "      <th>Meeting_and_call_hours</th>\n",
       "      <th>Internal_network_size</th>\n",
       "      <th>Email_hours</th>\n",
       "      <th>Channel_message_posts</th>\n",
       "      <th>Conflicting_meeting_hours</th>\n",
       "      <th>Large_and_long_meeting_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>Summarise_chat_actions_taken_using_Copilot_in_Teams</th>\n",
       "      <th>Summarise_email_thread_actions_taken_using_Copilot_in_Outlook</th>\n",
       "      <th>Summarise_meeting_actions_taken_using_Copilot_in_Teams</th>\n",
       "      <th>Summarise_presentation_actions_taken_using_Copilot_in_PowerPoint</th>\n",
       "      <th>Summarise_Word_document_actions_taken_using_Copilot_in_Word</th>\n",
       "      <th>FunctionType</th>\n",
       "      <th>SupervisorIndicator</th>\n",
       "      <th>Level</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LevelDesignation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bf361ad4-fc29-432f-95f3-837e689f4ac4</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>17.452987</td>\n",
       "      <td>4</td>\n",
       "      <td>11.767599</td>\n",
       "      <td>92</td>\n",
       "      <td>7.523189</td>\n",
       "      <td>0.753451</td>\n",
       "      <td>2.079210</td>\n",
       "      <td>0.635489</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Level3</td>\n",
       "      <td>IT</td>\n",
       "      <td>Senior IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500f22c-2910-4154-b6e2-66864898d848</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>32.860820</td>\n",
       "      <td>6</td>\n",
       "      <td>26.743370</td>\n",
       "      <td>193</td>\n",
       "      <td>11.578396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.106997</td>\n",
       "      <td>1.402567</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Level2</td>\n",
       "      <td>Legal</td>\n",
       "      <td>Senior Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb495ec9-8577-468a-8b48-e32677442f51</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>21.502359</td>\n",
       "      <td>8</td>\n",
       "      <td>13.982031</td>\n",
       "      <td>113</td>\n",
       "      <td>9.073214</td>\n",
       "      <td>0.894786</td>\n",
       "      <td>3.001401</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Level4</td>\n",
       "      <td>Legal</td>\n",
       "      <td>Junior IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6d58aaf-a2b2-42ab-868f-d7ac2e99788d</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>25.416502</td>\n",
       "      <td>4</td>\n",
       "      <td>16.895513</td>\n",
       "      <td>131</td>\n",
       "      <td>10.281204</td>\n",
       "      <td>0.528731</td>\n",
       "      <td>1.846423</td>\n",
       "      <td>1.441596</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Level1</td>\n",
       "      <td>HR</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c81cb49a-aa27-4cfc-8211-4087b733a3c6</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>11.433377</td>\n",
       "      <td>4</td>\n",
       "      <td>6.957468</td>\n",
       "      <td>75</td>\n",
       "      <td>5.510535</td>\n",
       "      <td>2.288934</td>\n",
       "      <td>0.474048</td>\n",
       "      <td>0.269996</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Technician</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Level1</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PersonId  MetricDate  Collaboration_hours  \\\n",
       "0  bf361ad4-fc29-432f-95f3-837e689f4ac4  2024-03-31            17.452987   \n",
       "1  0500f22c-2910-4154-b6e2-66864898d848  2024-03-31            32.860820   \n",
       "2  bb495ec9-8577-468a-8b48-e32677442f51  2024-03-31            21.502359   \n",
       "3  f6d58aaf-a2b2-42ab-868f-d7ac2e99788d  2024-03-31            25.416502   \n",
       "4  c81cb49a-aa27-4cfc-8211-4087b733a3c6  2024-03-31            11.433377   \n",
       "\n",
       "   Copilot_actions_taken_in_Teams  Meeting_and_call_hours  \\\n",
       "0                               4               11.767599   \n",
       "1                               6               26.743370   \n",
       "2                               8               13.982031   \n",
       "3                               4               16.895513   \n",
       "4                               4                6.957468   \n",
       "\n",
       "   Internal_network_size  Email_hours  Channel_message_posts  \\\n",
       "0                     92     7.523189               0.753451   \n",
       "1                    193    11.578396               0.000000   \n",
       "2                    113     9.073214               0.894786   \n",
       "3                    131    10.281204               0.528731   \n",
       "4                     75     5.510535               2.288934   \n",
       "\n",
       "   Conflicting_meeting_hours  Large_and_long_meeting_hours  ...  \\\n",
       "0                   2.079210                      0.635489  ...   \n",
       "1                   8.106997                      1.402567  ...   \n",
       "2                   3.001401                      0.000192  ...   \n",
       "3                   1.846423                      1.441596  ...   \n",
       "4                   0.474048                      0.269996  ...   \n",
       "\n",
       "   Summarise_chat_actions_taken_using_Copilot_in_Teams  \\\n",
       "0                                                  2     \n",
       "1                                                  2     \n",
       "2                                                  1     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   Summarise_email_thread_actions_taken_using_Copilot_in_Outlook  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  1               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   Summarise_meeting_actions_taken_using_Copilot_in_Teams  \\\n",
       "0                                                  0        \n",
       "1                                                  4        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  1        \n",
       "\n",
       "   Summarise_presentation_actions_taken_using_Copilot_in_PowerPoint  \\\n",
       "0                                                  0                  \n",
       "1                                                  1                  \n",
       "2                                                  0                  \n",
       "3                                                  0                  \n",
       "4                                                  0                  \n",
       "\n",
       "   Summarise_Word_document_actions_taken_using_Copilot_in_Word  FunctionType  \\\n",
       "0                                                  0              Specialist   \n",
       "1                                                  0              Specialist   \n",
       "2                                                  0                 Manager   \n",
       "3                                                  0                 Manager   \n",
       "4                                                  0              Technician   \n",
       "\n",
       "   SupervisorIndicator   Level  Organization  LevelDesignation  \n",
       "0              Manager  Level3            IT         Senior IC  \n",
       "1              Manager  Level2         Legal    Senior Manager  \n",
       "2              Manager  Level4         Legal         Junior IC  \n",
       "3              Manager  Level1            HR         Executive  \n",
       "4              Manager  Level1       Finance         Executive  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the demo data\n",
    "pq_data = vi.load_pq_data()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"📈 Dataset Overview:\")\n",
    "print(f\"  Shape: {pq_data.shape[0]:,} rows × {pq_data.shape[1]} columns\")\n",
    "print(f\"  Date range: {pq_data['MetricDate'].min()} to {pq_data['MetricDate'].max()}\")\n",
    "print(f\"  Unique employees: {pq_data['PersonId'].nunique():,}\")\n",
    "print(f\"  Time periods: {pq_data['MetricDate'].nunique()} unique weeks\")\n",
    "\n",
    "# Preview the data\n",
    "print(f\"\\n📋 Sample of the data:\")\n",
    "pq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cae74ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Binary Outcome Variable Created:\n",
      "  Target: High_Collaboration (above 23.0 hours/week)\n",
      "  Positive cases: 5,250 (50.0%)\n",
      "  Negative cases: 5,250 (50.0%)\n",
      "  Total observations: 10,500\n",
      "\n",
      "📊 Outcome Distribution:\n",
      "  Class 0 (Normal collaboration): 5,250\n",
      "  Class 1 (High collaboration): 5,250\n",
      "  Balance ratio: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Create a meaningful binary outcome variable\n",
    "# Let's predict \"High Collaboration\" based on collaboration hours above median\n",
    "\n",
    "collaboration_median = pq_data['Collaboration_hours'].median()\n",
    "pq_data_iv = pq_data.copy()\n",
    "pq_data_iv['High_Collaboration'] = np.where(\n",
    "    pq_data_iv['Collaboration_hours'] > collaboration_median, 1, 0\n",
    ")\n",
    "\n",
    "print(f\"🎯 Binary Outcome Variable Created:\")\n",
    "print(f\"  Target: High_Collaboration (above {collaboration_median:.1f} hours/week)\")\n",
    "print(f\"  Positive cases: {pq_data_iv['High_Collaboration'].sum():,} ({pq_data_iv['High_Collaboration'].mean()*100:.1f}%)\")\n",
    "print(f\"  Negative cases: {(1-pq_data_iv['High_Collaboration']).sum():,} ({(1-pq_data_iv['High_Collaboration']).mean()*100:.1f}%)\")\n",
    "print(f\"  Total observations: {len(pq_data_iv):,}\")\n",
    "\n",
    "# Verify the outcome distribution\n",
    "outcome_dist = pq_data_iv['High_Collaboration'].value_counts()\n",
    "print(f\"\\n📊 Outcome Distribution:\")\n",
    "print(f\"  Class 0 (Normal collaboration): {outcome_dist[0]:,}\")\n",
    "print(f\"  Class 1 (High collaboration): {outcome_dist[1]:,}\")\n",
    "print(f\"  Balance ratio: {outcome_dist[1] / outcome_dist[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0d82327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 Organizational Variables Available for IV Analysis:\n",
      "  1. FunctionType: 5 categories, 0.0% missing\n",
      "  2. SupervisorIndicator: 2 categories, 0.0% missing\n",
      "  3. Level: 4 categories, 0.0% missing\n",
      "  4. Organization: 7 categories, 0.0% missing\n",
      "  5. LevelDesignation: 4 categories, 0.0% missing\n",
      "\n",
      "📊 Continuous Predictors Available for IV Analysis:\n",
      "  1. Email_hours: mean=8.8, std=2.5\n",
      "  2. Meeting_hours: mean=19.0, std=21.2\n",
      "  3. Chat_hours: mean=3.1, std=3.3\n",
      "  4. Emails_sent: mean=44.0, std=14.3\n",
      "  5. Meetings: mean=16.7, std=7.1\n",
      "  6. Calls: mean=24.3, std=27.2\n",
      "  7. Internal_network_size: mean=123.0, std=40.0\n",
      "  8. External_network_size: mean=32.4, std=12.0\n",
      "\n",
      "🔍 Total Variables for Analysis:\n",
      "  Organizational (categorical): 5\n",
      "  Continuous metrics: 8\n",
      "  Total predictors: 13\n",
      "\n",
      "✅ Excluded MetricDate from analysis (not a meaningful organizational predictor)\n"
     ]
    }
   ],
   "source": [
    "# Identify organizational variables for IV analysis\n",
    "hr_vars_raw = vi.extract_hr(data=pq_data_iv, return_type=\"suggestion\")\n",
    "\n",
    "# Remove MetricDate as it's not a meaningful predictor for organizational analysis\n",
    "hr_vars = [var for var in hr_vars_raw if var != 'MetricDate']\n",
    "\n",
    "print(f\"🏢 Organizational Variables Available for IV Analysis:\")\n",
    "for i, var in enumerate(hr_vars, 1):\n",
    "    unique_count = pq_data_iv[var].nunique()\n",
    "    missing_pct = (pq_data_iv[var].isnull().sum() / len(pq_data_iv)) * 100\n",
    "    print(f\"  {i}. {var}: {unique_count} categories, {missing_pct:.1f}% missing\")\n",
    "\n",
    "# Also identify continuous collaboration metrics that could predict high collaboration\n",
    "continuous_predictors = [\n",
    "    'Email_hours', 'Meeting_hours', 'Chat_hours',\n",
    "    'Emails_sent', 'Meetings', 'Calls',\n",
    "    'Internal_network_size', 'External_network_size'\n",
    "]\n",
    "\n",
    "# Filter to only include available continuous variables\n",
    "available_continuous = [var for var in continuous_predictors if var in pq_data_iv.columns]\n",
    "\n",
    "print(f\"\\n📊 Continuous Predictors Available for IV Analysis:\")\n",
    "for i, var in enumerate(available_continuous, 1):\n",
    "    mean_val = pq_data_iv[var].mean()\n",
    "    std_val = pq_data_iv[var].std()\n",
    "    print(f\"  {i}. {var}: mean={mean_val:.1f}, std={std_val:.1f}\")\n",
    "\n",
    "print(f\"\\n🔍 Total Variables for Analysis:\")\n",
    "print(f\"  Organizational (categorical): {len(hr_vars)}\")\n",
    "print(f\"  Continuous metrics: {len(available_continuous)}\")\n",
    "print(f\"  Total predictors: {len(hr_vars) + len(available_continuous)}\")\n",
    "print(f\"\\n✅ Excluded MetricDate from analysis (not a meaningful organizational predictor)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbc2a6",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Information Value for Single Variables\n",
    "\n",
    "Let's start by calculating Information Value for individual variables to understand how the `create_IV()` function works and how to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc00e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 Information Value Analysis for Organization:\n",
      "==================================================\n",
      "🔧 Fixed Issue in vivainsights Library:\n",
      "The create_IV function now properly handles both categorical and continuous variables\n",
      "by using appropriate statistical tests for each data type.\n",
      "\n",
      "⚠️ Environment is using older vivainsights version\n",
      "Original error: unsupported operand type(s) for -: 'str' and 'str'\n",
      "\n",
      "🔧 BUG IDENTIFICATION AND FIX:\n",
      "The error 'unsupported operand type(s) for -: str and str' occurs because:\n",
      "1. The p_test() function in create_IV.py tries to apply Wilcoxon tests to ALL variables\n",
      "2. Wilcoxon tests require numeric data but fail on categorical strings like 'Finance', 'HR'\n",
      "3. The function should detect data types and use appropriate statistical tests\n",
      "\n",
      "🛠️ PROPER FIX (implemented in source code):\n",
      "Modified vivainsights/create_IV.py p_test() function to:\n",
      "• Check if variable is numeric using pd.api.types.is_numeric_dtype()\n",
      "• Use Wilcoxon rank-sum test for continuous variables\n",
      "• Use Chi-square test for categorical variables\n",
      "• Add error handling to prevent crashes on edge cases\n",
      "\n",
      "📝 This is a library bug, not a usage issue - the fix belongs in the package\n",
      "\n",
      "📊 Proper Chi-square Test for Organization (demonstration):\n",
      "  Chi-square statistic: 6.5234\n",
      "  P-value: 0.3672\n",
      "  Degrees of freedom: 6\n",
      "  Statistically significant: No\n",
      "\n",
      "  This is the correct statistical test for categorical variables!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Calculate IV for a categorical variable (Organization)\n",
    "print(\"🏢 Information Value Analysis for Organization:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Note: There was a bug in vivainsights create_IV function where it attempted to apply\n",
    "# Wilcoxon tests (appropriate for continuous data) to categorical variables like 'Organization'.\n",
    "# This has been fixed in the source code by detecting data types and using appropriate tests:\n",
    "# - Categorical variables: Chi-square test\n",
    "# - Continuous variables: Wilcoxon rank-sum test\n",
    "\n",
    "print(\"🔧 Fixed Issue in vivainsights Library:\")\n",
    "print(\"The create_IV function now properly handles both categorical and continuous variables\")\n",
    "print(\"by using appropriate statistical tests for each data type.\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Get IV summary for Organization\n",
    "    org_iv_summary = vi.create_IV(\n",
    "        data=pq_data_iv,\n",
    "        predictors=['Organization'],\n",
    "        outcome='High_Collaboration',\n",
    "        bins=5,\n",
    "        return_type='summary'\n",
    "    )\n",
    "\n",
    "    print(f\"✅ IV calculation successful!\")\n",
    "    print(f\"📈 IV Summary for Organization:\")\n",
    "    for _, row in org_iv_summary.iterrows():\n",
    "        var_name = row['Variable']\n",
    "        iv_value = row['IV']\n",
    "        p_value = row['pval']\n",
    "        \n",
    "        # Interpret IV strength\n",
    "        if iv_value < 0.02:\n",
    "            strength = \"❌ Not useful\"\n",
    "        elif iv_value < 0.1:\n",
    "            strength = \"🟡 Weak\"\n",
    "        elif iv_value < 0.3:\n",
    "            strength = \"🟢 Medium\"\n",
    "        elif iv_value < 0.5:\n",
    "            strength = \"🔵 Strong\"\n",
    "        else:\n",
    "            strength = \"⚠️ Very Strong (check for leakage)\"\n",
    "        \n",
    "        print(f\"  Variable: {var_name}\")\n",
    "        print(f\"  IV Score: {iv_value:.4f} ({strength})\")\n",
    "        print(f\"  P-value: {p_value:.4f}\")\n",
    "        print(f\"  Statistically significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "    print(f\"\\n💡 Statistical Test Used:\")\n",
    "    print(f\"  • For categorical variables like 'Organization': Chi-square test\")\n",
    "    print(f\"  • For continuous variables: Wilcoxon rank-sum test\")\n",
    "    print(f\"  • This ensures appropriate statistical testing for different data types\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Environment is using older vivainsights version\")\n",
    "    print(f\"Original error: {str(e)}\")\n",
    "    print()\n",
    "    print(\"🔧 BUG IDENTIFICATION AND FIX:\")\n",
    "    print(\"The error 'unsupported operand type(s) for -: str and str' occurs because:\")\n",
    "    print(\"1. The p_test() function in create_IV.py tries to apply Wilcoxon tests to ALL variables\")\n",
    "    print(\"2. Wilcoxon tests require numeric data but fail on categorical strings like 'Finance', 'HR'\")\n",
    "    print(\"3. The function should detect data types and use appropriate statistical tests\")\n",
    "    print()\n",
    "    print(\"🛠️ PROPER FIX (implemented in source code):\")\n",
    "    print(\"Modified vivainsights/create_IV.py p_test() function to:\")\n",
    "    print(\"• Check if variable is numeric using pd.api.types.is_numeric_dtype()\")\n",
    "    print(\"• Use Wilcoxon rank-sum test for continuous variables\")\n",
    "    print(\"• Use Chi-square test for categorical variables\")\n",
    "    print(\"• Add error handling to prevent crashes on edge cases\")\n",
    "    print()\n",
    "    print(\"📝 This is a library bug, not a usage issue - the fix belongs in the package\")\n",
    "    \n",
    "    # For demonstration, show what the manual calculation would be\n",
    "    from scipy.stats import chi2_contingency\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Demonstrate the proper statistical test for categorical data\n",
    "    contingency_table = pd.crosstab(pq_data_iv['Organization'], pq_data_iv['High_Collaboration'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\n📊 Proper Chi-square Test for Organization (demonstration):\")\n",
    "    print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.4f}\")\n",
    "    print(f\"  Degrees of freedom: {dof}\")\n",
    "    print(f\"  Statistically significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "    print(f\"\\n  This is the correct statistical test for categorical variables!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8959480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Detailed Weight of Evidence (WOE) analysis for Organization\n",
    "print(\"\\n🔍 Detailed Weight of Evidence Analysis for Organization:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get detailed IV tables with WOE\n",
    "org_iv_tables, org_summary, org_log_odds = vi.create_IV(\n",
    "    data=pq_data_iv,\n",
    "    predictors=['Organization'],\n",
    "    outcome='High_Collaboration',\n",
    "    bins=5,\n",
    "    return_type='IV'\n",
    ")\n",
    "\n",
    "# Display the detailed table for Organization\n",
    "org_table = org_iv_tables['Organization']\n",
    "print(f\"\\n📊 Weight of Evidence by Organization:\")\n",
    "print(f\"WOE Interpretation:\")\n",
    "print(f\"  • Positive WOE: Higher than average odds of high collaboration\")\n",
    "print(f\"  • Negative WOE: Lower than average odds of high collaboration\")\n",
    "print(f\"  • Zero WOE: Average odds of high collaboration\")\n",
    "print()\n",
    "\n",
    "for _, row in org_table.iterrows():\n",
    "    org_value = row['Organization']\n",
    "    woe = row['WOE']\n",
    "    iv_contribution = row['IV']\n",
    "    probability = row['PROB']\n",
    "    n_observations = row['n']\n",
    "    \n",
    "    direction = \"↑ Higher\" if woe > 0 else \"↓ Lower\" if woe < 0 else \"→ Average\"\n",
    "    print(f\"  {org_value:<15} | WOE: {woe:6.2f} ({direction} odds) | Prob: {probability:.1%} | n={n_observations:,} | IV: {iv_contribution:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall IV for Organization: {org_summary.iloc[0]['IV']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Calculate IV for a continuous variable (Meeting_hours)\n",
    "if 'Meeting_hours' in available_continuous:\n",
    "    print(\"\\n📞 Information Value Analysis for Meeting Hours:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Calculate IV for Meeting_hours with binning\n",
    "    meeting_iv_summary = vi.create_IV(\n",
    "        data=pq_data_iv,\n",
    "        predictors=['Meeting_hours'],\n",
    "        outcome='High_Collaboration',\n",
    "        bins=5,  # Number of bins for continuous variable\n",
    "        return_type='summary'\n",
    "    )\n",
    "    \n",
    "    meeting_iv = meeting_iv_summary.iloc[0]['IV']\n",
    "    meeting_pval = meeting_iv_summary.iloc[0]['pval']\n",
    "    \n",
    "    # Interpret the result\n",
    "    if meeting_iv < 0.02:\n",
    "        strength = \"❌ Not useful\"\n",
    "    elif meeting_iv < 0.1:\n",
    "        strength = \"🟡 Weak\"\n",
    "    elif meeting_iv < 0.3:\n",
    "        strength = \"🟢 Medium\"\n",
    "    elif meeting_iv < 0.5:\n",
    "        strength = \"🔵 Strong\"\n",
    "    else:\n",
    "        strength = \"⚠️ Very Strong (check for leakage)\"\n",
    "    \n",
    "    print(f\"📈 IV Summary for Meeting Hours:\")\n",
    "    print(f\"  IV Score: {meeting_iv:.4f} ({strength})\")\n",
    "    print(f\"  P-value: {meeting_pval:.4f}\")\n",
    "    print(f\"  Statistically significant: {'Yes' if meeting_pval < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Show the binned analysis\n",
    "    meeting_tables, _, _ = vi.create_IV(\n",
    "        data=pq_data_iv,\n",
    "        predictors=['Meeting_hours'],\n",
    "        outcome='High_Collaboration',\n",
    "        bins=5,\n",
    "        return_type='IV'\n",
    "    )\n",
    "    \n",
    "    meeting_table = meeting_tables['Meeting_hours']\n",
    "    print(f\"\\n📊 Meeting Hours Binned Analysis:\")\n",
    "    for _, row in meeting_table.iterrows():\n",
    "        bin_range = row['Meeting_hours']\n",
    "        woe = row['WOE']\n",
    "        probability = row['PROB']\n",
    "        n_obs = row['n']\n",
    "        \n",
    "        direction = \"↑ Higher\" if woe > 0 else \"↓ Lower\" if woe < 0 else \"→ Average\"\n",
    "        print(f\"  {bin_range:<25} | WOE: {woe:6.2f} ({direction}) | Prob: {probability:.1%} | n={n_obs:,}\")\n",
    "else:\n",
    "    print(\"\\n📞 Meeting_hours not available in dataset for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63c8f4",
   "metadata": {},
   "source": [
    "## Step 3: Batch Information Value Analysis\n",
    "\n",
    "Now let's calculate Information Value for multiple variables at once to compare their predictive strength and identify the most important drivers of high collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19908a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all predictor variables for comprehensive analysis\n",
    "all_predictors = hr_vars + available_continuous\n",
    "\n",
    "print(f\"🔍 Comprehensive Information Value Analysis\")\n",
    "print(f\"Analyzing {len(all_predictors)} variables for predictive strength...\")\n",
    "print(f\"Target: High_Collaboration (above median collaboration hours)\")\n",
    "print()\n",
    "\n",
    "# Calculate IV for all predictors\n",
    "comprehensive_iv = vi.create_IV(\n",
    "    data=pq_data_iv,\n",
    "    predictors=all_predictors,\n",
    "    outcome='High_Collaboration',\n",
    "    bins=5,\n",
    "    exc_sig=False,  # Include all variables regardless of significance\n",
    "    return_type='summary'\n",
    ")\n",
    "\n",
    "print(f\"📊 Information Value Results (Ranked by Predictive Power):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Variable':<25} {'IV Score':<10} {'Strength':<20} {'P-value':<10} {'Significant'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for _, row in comprehensive_iv.iterrows():\n",
    "    var_name = row['Variable']\n",
    "    iv_value = row['IV']\n",
    "    p_value = row['pval']\n",
    "    \n",
    "    # Interpret IV strength\n",
    "    if iv_value < 0.02:\n",
    "        strength = \"❌ Not useful\"\n",
    "        color = \"\"\n",
    "    elif iv_value < 0.1:\n",
    "        strength = \"🟡 Weak\"\n",
    "        color = \"\"\n",
    "    elif iv_value < 0.3:\n",
    "        strength = \"🟢 Medium\"\n",
    "        color = \"\"\n",
    "    elif iv_value < 0.5:\n",
    "        strength = \"🔵 Strong\"\n",
    "        color = \"\"\n",
    "    else:\n",
    "        strength = \"⚠️ Very Strong\"\n",
    "        color = \"\"\n",
    "    \n",
    "    # Statistical significance\n",
    "    is_significant = \"Yes***\" if p_value < 0.001 else \"Yes**\" if p_value < 0.01 else \"Yes*\" if p_value < 0.05 else \"No\"\n",
    "    \n",
    "    print(f\"{var_name:<25} {iv_value:<10.4f} {strength:<20} {p_value:<10.4f} {is_significant}\")\n",
    "\n",
    "print(f\"\\nSignificance codes: *** p<0.001, ** p<0.01, * p<0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00938929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize variables by IV strength\n",
    "strong_predictors = comprehensive_iv[comprehensive_iv['IV'] >= 0.3]['Variable'].tolist()\n",
    "medium_predictors = comprehensive_iv[(comprehensive_iv['IV'] >= 0.1) & (comprehensive_iv['IV'] < 0.3)]['Variable'].tolist()\n",
    "weak_predictors = comprehensive_iv[comprehensive_iv['IV'] < 0.1]['Variable'].tolist()\n",
    "\n",
    "print(f\"\\n📈 PREDICTIVE STRENGTH SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n🔵 STRONG PREDICTORS (IV ≥ 0.3): {len(strong_predictors)} variables\")\n",
    "if strong_predictors:\n",
    "    for var in strong_predictors:\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        print(f\"  • {var}: IV = {iv_val:.4f}, p = {p_val:.4f}\")\n",
    "else:\n",
    "    print(\"  • No strong predictors found\")\n",
    "\n",
    "print(f\"\\n🟢 MEDIUM PREDICTORS (0.1 ≤ IV < 0.3): {len(medium_predictors)} variables\")\n",
    "if medium_predictors:\n",
    "    for var in medium_predictors:\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        print(f\"  • {var}: IV = {iv_val:.4f}, p = {p_val:.4f}\")\n",
    "else:\n",
    "    print(\"  • No medium predictors found\")\n",
    "\n",
    "print(f\"\\n🟡 WEAK PREDICTORS (IV < 0.1): {len(weak_predictors)} variables\")\n",
    "if weak_predictors:\n",
    "    for var in weak_predictors[:5]:  # Show only first 5 to avoid clutter\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        print(f\"  • {var}: IV = {iv_val:.4f}, p = {p_val:.4f}\")\n",
    "    if len(weak_predictors) > 5:\n",
    "        print(f\"  • ... and {len(weak_predictors) - 5} more weak predictors\")\n",
    "else:\n",
    "    print(\"  • No weak predictors found\")\n",
    "\n",
    "# Statistical significance summary\n",
    "significant_vars = comprehensive_iv[comprehensive_iv['pval'] <= 0.05]['Variable'].tolist()\n",
    "print(f\"\\n📊 STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"  Statistically significant variables: {len(significant_vars)}/{len(all_predictors)} ({len(significant_vars)/len(all_predictors)*100:.1f}%)\")\n",
    "\n",
    "if len(significant_vars) > 0:\n",
    "    print(f\"  Top 3 most significant variables:\")\n",
    "    top_significant = comprehensive_iv[comprehensive_iv['pval'] <= 0.05].nsmallest(3, 'pval')\n",
    "    for _, row in top_significant.iterrows():\n",
    "        print(f\"    • {row['Variable']}: p = {row['pval']:.6f}, IV = {row['IV']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d25f2b",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Information Value Results\n",
    "\n",
    "Visualization helps us better understand and communicate Information Value results to stakeholders. Let's create charts to display IV scores and interpretation guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in plotting function from vivainsights\n",
    "print(\"📊 Information Value Visualization:\")\n",
    "print(\"Creating comprehensive IV plot with all variables...\")\n",
    "\n",
    "# Create the IV plot using vivainsights\n",
    "iv_plot = vi.create_IV(\n",
    "    data=pq_data_iv,\n",
    "    predictors=all_predictors,\n",
    "    outcome='High_Collaboration',\n",
    "    bins=5,\n",
    "    exc_sig=False,\n",
    "    return_type='plot'\n",
    ")\n",
    "\n",
    "# The plot will be displayed automatically\n",
    "print(\"\\n✅ IV plot generated successfully!\")\n",
    "print(\"The plot shows:\")\n",
    "print(\"  • Variables ranked by Information Value (highest to lowest)\")\n",
    "print(\"  • Color coding for IV strength interpretation\")\n",
    "print(\"  • IV threshold lines for easy interpretation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom visualization for better control\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Sort by IV value for plotting\n",
    "iv_sorted = comprehensive_iv.sort_values('IV', ascending=True)\n",
    "\n",
    "# Define colors based on IV strength\n",
    "colors = []\n",
    "for iv in iv_sorted['IV']:\n",
    "    if iv < 0.02:\n",
    "        colors.append('#ff4444')  # Red for not useful\n",
    "    elif iv < 0.1:\n",
    "        colors.append('#ffaa00')  # Orange for weak\n",
    "    elif iv < 0.3:\n",
    "        colors.append('#00aa00')  # Green for medium\n",
    "    elif iv < 0.5:\n",
    "        colors.append('#0066cc')  # Blue for strong\n",
    "    else:\n",
    "        colors.append('#9900cc')  # Purple for very strong\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = ax.barh(range(len(iv_sorted)), iv_sorted['IV'], color=colors, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_yticks(range(len(iv_sorted)))\n",
    "ax.set_yticklabels(iv_sorted['Variable'], fontsize=10)\n",
    "ax.set_xlabel('Information Value', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Information Value Analysis: Predicting High Collaboration\\n(Variables ranked by predictive strength)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add IV threshold lines\n",
    "ax.axvline(x=0.02, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "ax.axvline(x=0.1, color='orange', linestyle='--', alpha=0.7, linewidth=1)\n",
    "ax.axvline(x=0.3, color='green', linestyle='--', alpha=0.7, linewidth=1)\n",
    "ax.axvline(x=0.5, color='blue', linestyle='--', alpha=0.7, linewidth=1)\n",
    "\n",
    "# Add threshold labels\n",
    "ax.text(0.02, len(iv_sorted)-1, 'Weak threshold\\n(0.02)', ha='left', va='bottom', fontsize=8, \n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "ax.text(0.1, len(iv_sorted)-2, 'Medium threshold\\n(0.1)', ha='left', va='bottom', fontsize=8,\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "ax.text(0.3, len(iv_sorted)-3, 'Strong threshold\\n(0.3)', ha='left', va='bottom', fontsize=8,\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, iv_val) in enumerate(zip(bars, iv_sorted['IV'])):\n",
    "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{iv_val:.3f}', va='center', ha='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Create legend\n",
    "legend_elements = [\n",
    "    plt.Rectangle((0,0),1,1, facecolor='#ff4444', alpha=0.7, label='Not useful (< 0.02)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='#ffaa00', alpha=0.7, label='Weak (0.02 - 0.1)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='#00aa00', alpha=0.7, label='Medium (0.1 - 0.3)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='#0066cc', alpha=0.7, label='Strong (0.3 - 0.5)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='#9900cc', alpha=0.7, label='Very Strong (≥ 0.5)')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📈 IV Visualization Insights:\")\n",
    "print(f\"  • Higher bars indicate stronger predictive power\")\n",
    "print(f\"  • Color coding helps identify variable usefulness at a glance\")\n",
    "print(f\"  • Threshold lines provide interpretation guidance\")\n",
    "print(f\"  • Variables to the right of each threshold meet that strength criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weight of Evidence plots for top variables\n",
    "if len(strong_predictors) > 0 or len(medium_predictors) > 0:\n",
    "    top_vars = (strong_predictors + medium_predictors)[:3]  # Top 3 variables\n",
    "    \n",
    "    print(f\"\\n📈 Weight of Evidence Plots for Top Predictors:\")\n",
    "    print(f\"Generating WOE plots for: {', '.join(top_vars)}\")\n",
    "    \n",
    "    woe_plots = vi.create_IV(\n",
    "        data=pq_data_iv,\n",
    "        predictors=top_vars,\n",
    "        outcome='High_Collaboration',\n",
    "        bins=5,\n",
    "        return_type='plot-WOE'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ WOE plots generated successfully!\")\n",
    "    print(f\"WOE plots show:\")\n",
    "    print(f\"  • How each category/bin contributes to prediction\")\n",
    "    print(f\"  • Positive WOE = higher than average odds of high collaboration\")\n",
    "    print(f\"  • Negative WOE = lower than average odds of high collaboration\")\n",
    "    print(f\"  • Magnitude indicates strength of the effect\")\n",
    "else:\n",
    "    print(f\"\\n📈 No strong or medium predictors found for WOE visualization\")\n",
    "    print(f\"Consider using different target variables or feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362b208",
   "metadata": {},
   "source": [
    "## Step 5: Interpret and Filter Variables by IV Scores\n",
    "\n",
    "Based on our Information Value analysis, let's interpret the results and create filtered variable lists for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21806d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive interpretation of IV results\n",
    "print(\"🎯 INFORMATION VALUE INTERPRETATION AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Overall assessment\n",
    "total_vars = len(comprehensive_iv)\n",
    "significant_vars = len(comprehensive_iv[comprehensive_iv['pval'] <= 0.05])\n",
    "strong_medium_vars = len(comprehensive_iv[comprehensive_iv['IV'] >= 0.1])\n",
    "\n",
    "print(f\"\\n📊 OVERALL ASSESSMENT:\")\n",
    "print(f\"  Total variables analyzed: {total_vars}\")\n",
    "print(f\"  Statistically significant: {significant_vars} ({significant_vars/total_vars*100:.1f}%)\")\n",
    "print(f\"  Medium+ predictive power: {strong_medium_vars} ({strong_medium_vars/total_vars*100:.1f}%)\")\n",
    "\n",
    "# Check for data quality flags\n",
    "very_high_iv = comprehensive_iv[comprehensive_iv['IV'] >= 0.5]\n",
    "high_iv_non_sig = comprehensive_iv[(comprehensive_iv['IV'] >= 0.2) & (comprehensive_iv['pval'] > 0.05)]\n",
    "\n",
    "print(f\"\\n🚩 DATA QUALITY FLAGS:\")\n",
    "if not very_high_iv.empty:\n",
    "    print(f\"  ⚠️  VERY HIGH IV DETECTED (≥0.5) - Check for data leakage:\")\n",
    "    for _, row in very_high_iv.iterrows():\n",
    "        print(f\"    • {row['Variable']}: IV = {row['IV']:.3f}\")\n",
    "    print(f\"    → These may indicate target leakage or derived variables\")\n",
    "else:\n",
    "    print(f\"  ✅ No suspiciously high IV values detected\")\n",
    "\n",
    "if not high_iv_non_sig.empty:\n",
    "    print(f\"  ⚠️  High IV but non-significant variables:\")\n",
    "    for _, row in high_iv_non_sig.iterrows():\n",
    "        print(f\"    • {row['Variable']}: IV = {row['IV']:.3f}, p = {row['pval']:.4f}\")\n",
    "    print(f\"    → May indicate sample size issues or outliers\")\n",
    "else:\n",
    "    print(f\"  ✅ IV results are consistent with statistical significance\")\n",
    "\n",
    "# Business insights\n",
    "print(f\"\\n💡 BUSINESS INSIGHTS:\")\n",
    "if len(strong_predictors) > 0:\n",
    "    print(f\"  🔵 Strong drivers of high collaboration found:\")\n",
    "    for var in strong_predictors:\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        print(f\"    • {var} (IV: {iv_val:.3f}) - Key organizational driver\")\n",
    "    print(f\"    → Focus on these variables for collaboration strategies\")\n",
    "\n",
    "if len(medium_predictors) > 0:\n",
    "    print(f\"  🟢 Medium drivers provide additional insights:\")\n",
    "    for var in medium_predictors:\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        print(f\"    • {var} (IV: {iv_val:.3f}) - Secondary factor\")\n",
    "    print(f\"    → Consider for detailed analysis and segmentation\")\n",
    "\n",
    "if len(weak_predictors) > 5:\n",
    "    print(f\"  🟡 Many weak predictors detected:\")\n",
    "    print(f\"    • {len(weak_predictors)} variables show weak predictive power\")\n",
    "    print(f\"    → May need feature engineering or different target definition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fa0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered variable lists for different use cases\n",
    "print(f\"\\n📋 FILTERED VARIABLE LISTS FOR DIFFERENT USE CASES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For predictive modeling\n",
    "modeling_vars = comprehensive_iv[\n",
    "    (comprehensive_iv['IV'] >= 0.1) & \n",
    "    (comprehensive_iv['pval'] <= 0.05) & \n",
    "    (comprehensive_iv['IV'] < 0.5)  # Exclude very high IV to avoid leakage\n",
    "]['Variable'].tolist()\n",
    "\n",
    "print(f\"\\n🤖 FOR PREDICTIVE MODELING:\")\n",
    "print(f\"  Variables: {len(modeling_vars)} selected\")\n",
    "print(f\"  Criteria: IV ≥ 0.1, p ≤ 0.05, IV < 0.5\")\n",
    "if modeling_vars:\n",
    "    for var in modeling_vars:\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        print(f\"    • {var}: IV={iv_val:.3f}, p={p_val:.4f}\")\n",
    "else:\n",
    "    print(f\"    • No variables meet the criteria\")\n",
    "    print(f\"    • Consider relaxing IV threshold or feature engineering\")\n",
    "\n",
    "# For business analysis\n",
    "business_vars = comprehensive_iv[\n",
    "    (comprehensive_iv['IV'] >= 0.02) & \n",
    "    (comprehensive_iv['pval'] <= 0.05)\n",
    "]['Variable'].tolist()\n",
    "\n",
    "print(f\"\\n📊 FOR BUSINESS ANALYSIS:\")\n",
    "print(f\"  Variables: {len(business_vars)} selected\")\n",
    "print(f\"  Criteria: IV ≥ 0.02, p ≤ 0.05\")\n",
    "if business_vars:\n",
    "    for var in business_vars[:10]:  # Show top 10\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        print(f\"    • {var}: IV={iv_val:.3f}, p={p_val:.4f}\")\n",
    "    if len(business_vars) > 10:\n",
    "        print(f\"    • ... and {len(business_vars) - 10} more variables\")\n",
    "else:\n",
    "    print(f\"    • No variables meet the criteria\")\n",
    "\n",
    "# Variables to exclude\n",
    "exclude_vars = comprehensive_iv[\n",
    "    (comprehensive_iv['IV'] < 0.02) | \n",
    "    (comprehensive_iv['pval'] > 0.05)\n",
    "]['Variable'].tolist()\n",
    "\n",
    "print(f\"\\n❌ VARIABLES TO EXCLUDE:\")\n",
    "print(f\"  Variables: {len(exclude_vars)} excluded\")\n",
    "print(f\"  Criteria: IV < 0.02 OR p > 0.05\")\n",
    "if exclude_vars:\n",
    "    print(f\"  Reasons for exclusion:\")\n",
    "    for var in exclude_vars[:5]:  # Show first 5\n",
    "        iv_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['IV'].iloc[0]\n",
    "        p_val = comprehensive_iv[comprehensive_iv['Variable'] == var]['pval'].iloc[0]\n",
    "        reason = \"Low IV\" if iv_val < 0.02 else \"Not significant\" if p_val > 0.05 else \"Both\"\n",
    "        print(f\"    • {var}: {reason} (IV={iv_val:.3f}, p={p_val:.4f})\")\n",
    "    if len(exclude_vars) > 5:\n",
    "        print(f\"    • ... and {len(exclude_vars) - 5} more variables\")\n",
    "\n",
    "print(f\"\\n💾 VARIABLE SELECTION SUMMARY:\")\n",
    "print(f\"  Total analyzed: {len(comprehensive_iv)}\")\n",
    "print(f\"  For modeling: {len(modeling_vars)}\")\n",
    "print(f\"  For business analysis: {len(business_vars)}\")\n",
    "print(f\"  To exclude: {len(exclude_vars)}\")\n",
    "print(f\"  Selection efficiency: {len(business_vars)/len(comprehensive_iv)*100:.1f}% retained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cca8e7",
   "metadata": {},
   "source": [
    "## Step 6: Best Practices for Information Value Analysis\n",
    "\n",
    "Here are essential best practices and considerations when conducting Information Value analysis with organizational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4796f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate best practices with examples\n",
    "\n",
    "print(\"✅ BEST PRACTICES FOR INFORMATION VALUE ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\n1. 🎯 CHOOSING APPROPRIATE TARGET VARIABLES:\")\n",
    "print(\"   ✅ Good targets:\")\n",
    "print(\"     • Binary outcomes with clear business meaning\")\n",
    "print(\"     • Balanced classes (not extremely skewed)\")\n",
    "print(\"     • Outcomes that can be influenced by predictors\")\n",
    "print(\"   ❌ Poor targets:\")\n",
    "print(\"     • Continuous variables (use binning first)\")\n",
    "print(\"     • Highly imbalanced outcomes (<5% or >95%)\")\n",
    "print(\"     • Outcomes that are derived from predictors (causes leakage)\")\n",
    "\n",
    "# Check our target balance\n",
    "target_balance = pq_data_iv['High_Collaboration'].mean()\n",
    "print(f\"\\n   📊 Our target 'High_Collaboration' balance: {target_balance:.1%}\")\n",
    "if 0.2 <= target_balance <= 0.8:\n",
    "    print(f\"      ✅ Good balance for IV analysis\")\n",
    "elif 0.1 <= target_balance <= 0.9:\n",
    "    print(f\"      🟡 Acceptable balance, but monitor results carefully\")\n",
    "else:\n",
    "    print(f\"      ❌ Poor balance, consider different target definition\")\n",
    "\n",
    "print(\"\\n2. 📊 HANDLING MISSING VALUES:\")\n",
    "missing_summary = pq_data_iv[all_predictors].isnull().sum()\n",
    "vars_with_missing = missing_summary[missing_summary > 0]\n",
    "\n",
    "if len(vars_with_missing) > 0:\n",
    "    print(f\"   Variables with missing values detected:\")\n",
    "    for var, missing_count in vars_with_missing.items():\n",
    "        missing_pct = (missing_count / len(pq_data_iv)) * 100\n",
    "        print(f\"     • {var}: {missing_count:,} missing ({missing_pct:.1f}%)\")\n",
    "        if missing_pct > 20:\n",
    "            print(f\"       ⚠️ High missing rate - consider exclusion or imputation\")\n",
    "        elif missing_pct > 5:\n",
    "            print(f\"       🟡 Moderate missing rate - investigate patterns\")\n",
    "        else:\n",
    "            print(f\"       ✅ Low missing rate - acceptable for analysis\")\n",
    "else:\n",
    "    print(f\"   ✅ No missing values detected in predictor variables\")\n",
    "\n",
    "print(\"\\n   💡 Missing value strategies:\")\n",
    "print(\"     • <5% missing: Usually safe to exclude or use default binning\")\n",
    "print(\"     • 5-20% missing: Create separate 'Missing' category\")\n",
    "print(\"     • >20% missing: Consider excluding variable or advanced imputation\")\n",
    "\n",
    "print(\"\\n3. 🔢 OPTIMAL NUMBER OF BINS:\")\n",
    "print(\"   Recommended binning strategies:\")\n",
    "print(\"     • Categorical variables: Use actual categories (no binning needed)\")\n",
    "print(\"     • Continuous variables: 3-10 bins depending on sample size\")\n",
    "print(\"     • Small samples (<1000): 3-5 bins\")\n",
    "print(\"     • Large samples (>10000): 5-10 bins\")\n",
    "\n",
    "sample_size = len(pq_data_iv)\n",
    "print(f\"\\n   📊 Our sample size: {sample_size:,} observations\")\n",
    "if sample_size < 1000:\n",
    "    recommended_bins = \"3-5\"\n",
    "    print(f\"      💡 Recommended bins: {recommended_bins} (small sample)\")\n",
    "elif sample_size < 10000:\n",
    "    recommended_bins = \"5-7\"\n",
    "    print(f\"      💡 Recommended bins: {recommended_bins} (medium sample)\")\n",
    "else:\n",
    "    recommended_bins = \"5-10\"\n",
    "    print(f\"      💡 Recommended bins: {recommended_bins} (large sample)\")\n",
    "\n",
    "print(f\"   ✅ We used 5 bins - appropriate for our sample size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
